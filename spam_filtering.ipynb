{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8328829",
   "metadata": {},
   "source": [
    "# Spam Filtering using Naïve Bayes Classifier in R\n",
    "\n",
    "Download dataset from https://plg.uwaterloo.ca/~gvcormac/treccorpus06/ and \n",
    "check <b>Instructions</b> on the Main Program section before re-running this notebook.\n",
    "\n",
    "<h2> Part 1: Functions Definitions </h2>\n",
    "\n",
    "<h4> Function: setup_dataset </h4>\n",
    "This function divides the dataset (trec06p) into training set (70%) and test set (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6803560",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dataset <- function(inputfile){\n",
    "    dataset <<- scan(file=inputfile, list(type=\"\", doc=\"\")) # 1st col: spam/ham; 2nd col: document filename\n",
    "    dataset$doc <<- paste(data_dir, dataset$doc, sep=\"/\");\n",
    "    N <- length(dataset$doc)\n",
    "    N_vec <- seq(1:length(dataset$doc))\n",
    "    trainingset_idx <<- N_vec[(1:N-1)%%10<7] # using modulo, Document no. 1,2,3,4,5,6,7,...,11,12,.....\n",
    "    testset_idx <<- N_vec[(1:N-1)%%10>=7] # using modulo, Document no. 8,9,10,...,18,19,20,...,28,..\n",
    "    print(paste(\"Count of all documents: \", N))\n",
    "    print(paste(\"Count of training set: \", length(trainingset_idx)))\n",
    "    print(paste(\"Count of test set: \", length(testset_idx)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb1169",
   "metadata": {},
   "source": [
    "<h4> Function: parse_document </h4>\n",
    "This function reads each document from the dataset and parses each word. It also removes words from the document that will not help in the training, e.g. html tags etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d10a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_document <- function(document, normal){\n",
    "    words <- c()\n",
    "    words <- scan(file=document, \"\", quote = \"\") # scan document per word (delimited by space)\n",
    "    words <- gsub(\"<.*>|.*=.*>|&nbsp;\", \"\", words, perl=TRUE) # remove html tags\n",
    "    words <- grep(\"^[\\\"]*[a-zA-Z]+[,.\\\"]*$\", words, perl=TRUE, value=TRUE) # select only alpha strings, with quotes or ending with ., are ok\n",
    "    words <- words[nchar(words)>2 & nchar(words)<50] # select only strings that have 3-49 letters\n",
    "\n",
    "    words <- unique(tolower(gsub(\"[^[:alnum:]_]\", \"\", words))) # remove punctuations in the words, make all lowercase and unique\t\n",
    "    words <- words[nchar(words)>2]\n",
    "    words <- words[words!=\"\"] # remove empty strings in the vector\n",
    "    words\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d9927a",
   "metadata": {},
   "source": [
    "<h4> Function: construct_vocabulary </h4>\n",
    "This functions constructs vocabulary.txt based on words on training set documents. It counts how many times each word appears as spam and as ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba1caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_vocabulary <- function(vocabularyfile, normal){\n",
    "    vocabulary <- c()\n",
    "    wordctr_spam <- c()\n",
    "    wordctr_ham <- c()\n",
    "\n",
    "    L <- length(trainingset_idx)\n",
    "    partition <- 52\n",
    "    cleanup_ctr <- 1\n",
    "    lowerbound <- 1\n",
    "    for(i in 1:L){ \n",
    "        if (i %% 1000 == 1 || i == L)\n",
    "            message(paste(\"Parsing training set document #\",i))\n",
    "        idx <- trainingset_idx[i];\n",
    "        words <- parse_document(dataset$doc[idx], normal) # parse words on each documents in the training set\n",
    "\n",
    "        newwords <- setdiff(words,vocabulary);\n",
    "        wordctr_spam[newwords] <- 0 # initialize new words to 0, so can iterate properly\n",
    "        wordctr_ham[newwords] <- 0\n",
    "\n",
    "        if(dataset$type[idx] == \"spam\"){ # if current document is spam (ham), iterate wordctr_spam (wordctr_ham) for all words in the document\n",
    "            wordctr_spam[words] <- wordctr_spam[words]+1\n",
    "        }else{\n",
    "            wordctr_ham[words] <- wordctr_ham[words]+1\n",
    "        }\n",
    "\n",
    "        vocabulary <- append(vocabulary, newwords) # add new words to the current vocabulary\n",
    "\n",
    "    }\n",
    "\n",
    "    # this block is only for: improving classifier\n",
    "    if(!normal){\n",
    "        # remove least frequent words\n",
    "        wordctr_total <- wordctr_spam+wordctr_ham\n",
    "        wordctr_total <- wordctr_total[wordctr_total>50]\n",
    "        vocabulary <- names(wordctr_total)\n",
    "        wordctr_spam <- wordctr_spam[vocabulary]\n",
    "        wordctr_ham <- wordctr_ham[vocabulary]\n",
    "\n",
    "        # remove 200 most frequent words\n",
    "        wordctr_total <- wordctr_spam+wordctr_ham\n",
    "        wordctr_total <- sort(wordctr_total, decreasing=TRUE)\n",
    "        wordctr_total <- wordctr_total[201:length(wordctr_total)]\n",
    "        vocabulary <- names(wordctr_total)\n",
    "        wordctr_spam <- wordctr_spam[vocabulary]\n",
    "        wordctr_ham <- wordctr_ham[vocabulary]\n",
    "\n",
    "        # take biggest differences\n",
    "        wordctr_diff <- abs(wordctr_spam-wordctr_ham)\n",
    "        wordctr_diff <- sort(wordctr_total, decreasing=TRUE)\n",
    "        wordctr_diff <- wordctr_diff[1:200]\n",
    "        vocabulary <- names(wordctr_diff)\n",
    "        wordctr_spam <- wordctr_spam[vocabulary]\n",
    "        wordctr_ham <- wordctr_ham[vocabulary]\n",
    "    }\n",
    "\n",
    "    vocabulary <- sort(vocabulary)\n",
    "    write(paste(vocabulary, wordctr_spam[vocabulary], wordctr_ham[vocabulary], sep=\",\"), vocabularyfile) # write to a file, space delimited\n",
    "    print(paste0(\"New vocabulary is saved to \", vocabularyfile, \".\"))\n",
    "\n",
    "    # make scope:global\n",
    "    vocabulary <<- vocabulary\n",
    "    wordctr_spam <<- wordctr_spam[vocabulary]\n",
    "    wordctr_ham <<- wordctr_ham[vocabulary]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c84b4d",
   "metadata": {},
   "source": [
    "<h4> Function: load_vocabulary </h4>\n",
    "This function load vocabulary.txt (for option to load existing vocabulary from file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bedbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_vocabulary <- function(vocabularyfile){\n",
    "    v <- scan(file=vocabularyfile, list(w=\"\", s=0, h=0), sep=\",\")\n",
    "    vocabulary <<- v$w\n",
    "    wordctr_spam <<- v$s\n",
    "    names(wordctr_spam) <<- vocabulary # set the vocabulary words as the index for the ctr\n",
    "    wordctr_ham <<- v$h\n",
    "    names(wordctr_ham) <<- vocabulary # set the vocabulary words as the index for the ctr\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db133716",
   "metadata": {},
   "source": [
    "<h4> Functions: compute_priors and compute_likelihoods </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c51fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_priors <- function(){\n",
    "    N <- length(dataset$type[trainingset_idx]) # total # of training set\n",
    "    S <- table(dataset$type[trainingset_idx])[\"spam\"] # total # of spam docs in training set\n",
    "    H <- table(dataset$type[trainingset_idx])[\"ham\"] # total # of ham docs in training set\n",
    "    prior_spam <<- S/N # spam docs / all docs\n",
    "    prior_ham <<- H/N # ham docs / all docs\n",
    "}\n",
    "\n",
    "compute_likelihoods <- function(index){\n",
    "    lambda <- lambdalist[index]\n",
    "    S <- table(dataset$type[trainingset_idx])[\"spam\"] # total # of spam docs in training set\n",
    "    H <- table(dataset$type[trainingset_idx])[\"ham\"] # total # of ham docs in training set\n",
    "    V <- length(vocabulary) # size of vocabulary\n",
    "    likelihood_spam[index,] <<- (wordctr_spam+lambda)/(S+lambda*V) # spam docs where the each word appeared / all spam docs \n",
    "    likelihood_ham[index,] <<- (wordctr_ham+lambda)/(H+lambda*V) # ham docs where the each word appeared / all ham docs\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b4a9ea",
   "metadata": {},
   "source": [
    "<h4> Functions: iterate_precision_recall, compute_precision and compute_recall </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b12d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate_precision_recall <- function(true_value, classification, index){\n",
    "    if(true_value == \"spam\"){\n",
    "        if(classification == \"spam\")\n",
    "            true_pos[index] <<- true_pos[index]+1 # spam msgs classified as spam\n",
    "        else\n",
    "            false_neg[index] <<- false_neg[index]+1 # spam msgs misclassified as ham\n",
    "    }else if(true_value == \"ham\"){\n",
    "        if(classification == \"ham\")\n",
    "            true_neg[index] <<- true_neg[index]+1 # ham msgs classified as ham\n",
    "        else\n",
    "            false_pos[index] <<- false_pos[index]+1 # ham msgs misclassified as spam\n",
    "    }\n",
    "}\n",
    "\n",
    "compute_precision <- function(index){\n",
    "    precision <- true_pos[index]/(true_pos[index]+false_pos[index])\n",
    "    precision\n",
    "}\n",
    "\n",
    "compute_recall <- function(index){\n",
    "    recall <- true_pos[index]/(true_pos[index]+false_neg[index])\n",
    "    recall\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec7df6",
   "metadata": {},
   "source": [
    "<h4> Function: run_classifier </h4>\n",
    "This function runs Naive Bayes Classifier on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e85cfc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classifier <- function(filename, normal){\n",
    "    L <- length(lambdalist)\n",
    "\n",
    "    # initialize output files to be used, 1 per lambda value\n",
    "    outputfile <- rep(\"\", times=L)\n",
    "    names(outputfile) <- lambdalist\n",
    "    for(i in 1:L){\n",
    "        lambda <- lambdalist[i]\n",
    "        fmt_lambda <- sprintf(\"%.3f\", lambda);\n",
    "        outputfile[i] <- paste(filename, fmt_lambda, \"txt\", sep=\".\")\n",
    "    }\n",
    "\n",
    "    classification <- matrix(data=\"\", nrow=length(lambdalist), ncol=length(testset_idx), byrow=FALSE)\n",
    "\n",
    "    # initialize precision & recall counters\n",
    "    true_pos <<- rep(0, times=L)\n",
    "    false_pos <<- rep(0, times=L)\n",
    "    true_neg <<- rep(0, times=L)\n",
    "    false_neg <<- rep(0, times=L)\n",
    "    precision <<- rep(0, times=L)\n",
    "    recall <<- rep(0, times=L)\n",
    "\n",
    "    # calculate posteriori probabilities for each documents in the test set\n",
    "    for(j in 1:length(testset_idx)){\n",
    "        if (j %% 500 == 1 || j == length(testset_idx))\n",
    "            message(paste(\"Parsing test set document #\",j))\n",
    "\n",
    "        idx <- testset_idx[j]\n",
    "        words <- parse_document(dataset$doc[idx], normal)\n",
    "        vocab_present <- intersect(vocabulary, words) # vocab words present in document\n",
    "        vocab_absent <- setdiff(vocabulary, words) # vocab words absent in document\n",
    "\n",
    "        # calculate for each lambda\n",
    "        for(i in 1:L){\n",
    "            lxplog_spam <- sum(log(likelihood_spam[i,vocab_present]))+sum(log(1-likelihood_spam[i,vocab_absent]))+log(prior_spam) # log of P(D|w=S)*P(w=S)\n",
    "            lxplog_ham <- sum(log(likelihood_ham[i,vocab_present]))+sum(log(1-likelihood_ham[i,vocab_absent]))+log(prior_ham) # log of P(D|w=H)*P(w=H)\n",
    "            # note: actual probabilities:\n",
    "            #     P(w=S|D) is exp(lxplog_spam)/(exp(lxplog_spam)+exp(lxplog_ham))\n",
    "            #     P(w=H|D) is exp(lxplog_ham)/(exp(lxplog_spam)+exp(lxplog_ham))\n",
    "            # however, due to the very small values (approaching zero) which will cause loss of accuracy on the results, \n",
    "            # I decided to simplify the equation, divide out the denominators, and just compare the exponent of the numerators: \n",
    "            # since: exp(-n) > (<) exp(-m) is equal to -n > (<) -m\n",
    "            probability_spam <- lxplog_spam\n",
    "            probability_ham <- lxplog_ham\n",
    "\n",
    "            if(is.na(probability_spam) || is.na(probability_ham)){\n",
    "                classification[i,j] <- \"ham\" # if can't classify, assume as ham\n",
    "            }else if(probability_spam > probability_ham){\n",
    "                classification[i,j] <- \"spam\"\n",
    "            }else if(probability_spam < probability_ham){\n",
    "                classification[i,j] <- \"ham\"\n",
    "            }else{\n",
    "                classification[i,j] <- \"ham\" # if can't classify, assume as ham\n",
    "            }\n",
    "\n",
    "            iterate_precision_recall(dataset$type[idx], classification[i,j], i)\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # dump to files the following:\n",
    "    #     filename, true classification, computed classification\n",
    "    #     report precision and recall for each lambdas\n",
    "    for(i in 1:L){\n",
    "        write(paste(dataset$doc[testset_idx], dataset$type[testset_idx], classification[i,], sep=\" \"), outputfile[i]) # write to a file, space delimited\n",
    "        cat(paste0(\"[Lambda \", lambdalist[i], \"]\\tHam/Spam predictions are saved to \", outputfile[i], \".\"), sep=\"\\n\")\n",
    "\n",
    "        precision[i] <<- compute_precision(i)\n",
    "        recall[i] <<- compute_recall(i)\n",
    "        cat(\"\\n\\n\", file=outputfile[i], fill=TRUE, append=TRUE)\n",
    "        cat(paste(precision[i], recall[i]), file=outputfile[i], fill=TRUE, append=TRUE)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554af4f2",
   "metadata": {},
   "source": [
    "<h2>Part 2: Main Program</h2>\n",
    "\n",
    "<h4>Instructions for user:</h4>\n",
    "<ul>\n",
    "    <li>Specify in <b>default_dir</b> the location of your code and files.</li>\n",
    "    <li>Specify in <b>data_dir</b> the location of your trec06p dataset. Note, this is only tested on trec06p dataset and using a different corpus with different formatting might need parsing changes.</li>\n",
    "    <li>Specify in <b>working_dir</b> the directory location of labels file, and where the output files of this program should be saved.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb12ce89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Count of all documents:  37822\"\n",
      "[1] \"Count of training set:  26476\"\n",
      "[1] \"Count of test set:  11346\"\n"
     ]
    }
   ],
   "source": [
    "default_dir <- '/'\n",
    "data_dir <- paste(default_dir, \"trec06p\", sep=\"/\")\n",
    "working_dir <- paste(default_dir, \"results\", sep=\"/\")\n",
    "setwd(working_dir)\n",
    "\n",
    "setup_dataset(\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b0683e",
   "metadata": {},
   "source": [
    "<h4> Instructions for user: </h4>\n",
    "\n",
    "<b>MENU 1:</b> This program can be run with different settings. Change the value of <b>choice1</b> based on your run preference.\n",
    "<ol>\n",
    "    <li>No Lambda Smoothing</li>\n",
    "    <li>With Lambda Smoothing (run on all lambdas)</li>\n",
    "    <li>200 Most Informative Words</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea2f7298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Selected: [2] With Lambda Smoothing (run on all lambdas)\"\n"
     ]
    }
   ],
   "source": [
    "choice1 <- 2  # change this value based on the run setting preferred\n",
    "\n",
    "if (choice1 == 1) {\n",
    "    print(\"Selected: [1] No Lambda Smoothing\")\n",
    "    lambdalist <- c(0.000)\n",
    "    vocabfile <- \"vocabulary.txt\"\n",
    "    outfile <- \"result\"\n",
    "    normal <- TRUE\n",
    "} else if (choice1 == 2) {\n",
    "    print(\"Selected: [2] With Lambda Smoothing (run on all lambdas)\")\n",
    "    lambdalist <- c(0.005, 0.100, 0.500, 1.000, 2.000)\n",
    "    vocabfile <- \"vocabulary.txt\"\n",
    "    outfile <- \"result\"\n",
    "    normal <- TRUE\n",
    "} else if (choice1 == 3) {\n",
    "    print(\"Selected: [3] 200 Most Informative Words\")\n",
    "    lambdalist <- c(0.500)\n",
    "    vocabfile <- \"vocabulary.200.txt\"\n",
    "    outfile <- \"result_200\"\n",
    "    normal <- FALSE\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8090d4f",
   "metadata": {},
   "source": [
    "<h4> Instructions for user: </h4>\n",
    "\n",
    "<b>MENU 2:</b> This program can be run with different settings. Change the value of <b>choice2</b> based on your run preference.\n",
    "<ol>\n",
    "    <li>Construct new vocabulary</li>\n",
    "    <li>Load vocabulary from file (requires existing vocabulary.txt)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdbb16d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Selected: [2] Load vocabulary from file\"\n",
      "[1] \"Loading vocabulary from file...\"\n",
      "[1] \"Sat Sep 18 15:09:18 2021\"\n"
     ]
    }
   ],
   "source": [
    "choice2 <- 2 # change this value based on the run setting preferred\n",
    "\n",
    "if (choice2 == 1) {\n",
    "    print(\"Selected: [1] Construct new vocabulary\")\n",
    "    print(\"Constructing vocabulary from training set.\")\n",
    "    print(\"This might take a while...\")\n",
    "    construct_vocabulary(vocabfile,normal)\n",
    "    print(date())\n",
    "} else {\n",
    "    print(\"Selected: [2] Load vocabulary from file\")\n",
    "    print(\"Loading vocabulary from file...\")\n",
    "    load_vocabulary(vocabfile)\n",
    "    print(date())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1835bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Computing priors and likelihoods...\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing priors and likelihoods...\")\n",
    "compute_priors()\n",
    "# compute likelihoods for all lambdas, computed simultaneously for faster processing time\n",
    "# initializing\n",
    "likelihood_spam <- matrix(data=0, nrow=length(lambdalist), ncol=length(vocabulary), byrow=FALSE, dimnames=list(c(1:length(lambdalist)), vocabulary))\n",
    "likelihood_ham <- matrix(data=0, nrow=length(lambdalist), ncol=length(vocabulary), byrow=FALSE, dimnames=list(c(1:length(lambdalist)), vocabulary))\n",
    "for(i in 1:length(lambdalist))\n",
    "    compute_likelihoods(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f992f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Classifying documents on test set.\"\n",
      "[1] \"This might take a while...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing test set document # 1\n",
      "Parsing test set document # 501\n",
      "Parsing test set document # 1001\n",
      "Parsing test set document # 1501\n",
      "Parsing test set document # 2001\n",
      "Parsing test set document # 2501\n",
      "Parsing test set document # 3001\n",
      "Parsing test set document # 3501\n",
      "Parsing test set document # 4001\n",
      "Parsing test set document # 4501\n",
      "Parsing test set document # 5001\n",
      "Parsing test set document # 5501\n",
      "Parsing test set document # 6001\n",
      "Parsing test set document # 6501\n",
      "Parsing test set document # 7001\n",
      "Warning message in scan(file = document, \"\", quote = \"\"):\n",
      "“embedded nul(s) found in input”Parsing test set document # 7501\n",
      "Parsing test set document # 8001\n",
      "Parsing test set document # 8501\n",
      "Parsing test set document # 9001\n",
      "Parsing test set document # 9501\n",
      "Parsing test set document # 10001\n",
      "Parsing test set document # 10501\n",
      "Parsing test set document # 11001\n",
      "Parsing test set document # 11346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lambda 0.005]\tHam/Spam predictions are saved to result.0.005.txt.\n",
      "[Lambda 0.1]\tHam/Spam predictions are saved to result.0.100.txt.\n",
      "[Lambda 0.5]\tHam/Spam predictions are saved to result.0.500.txt.\n",
      "[Lambda 1]\tHam/Spam predictions are saved to result.1.000.txt.\n",
      "[Lambda 2]\tHam/Spam predictions are saved to result.2.000.txt.\n",
      "\n",
      "\n",
      "Precision and recall of the test set per lambda.\n",
      "\n",
      "[L]\t[P]\t[R]\n",
      "0.005\t0.9603\t0.983\n",
      "0.1\t0.9826\t0.9785\n",
      "0.5\t0.9937\t0.9821\n",
      "1\t0.9931\t0.984\n",
      "2\t0.9915\t0.9863\n",
      "\n",
      "It is also saved in precision_recall_report.txt.\n",
      "Sat Sep 18 15:31:33 2021"
     ]
    }
   ],
   "source": [
    "print(\"Classifying documents on test set.\")\n",
    "print(\"This might take a while...\")\n",
    "run_classifier(outfile, normal)\n",
    "# print precision recall in separate file\n",
    "cat(lambdalist, file=\"precision_recall_report.txt\", fill=TRUE, append=FALSE)\n",
    "cat(precision, file=\"precision_recall_report.txt\", fill=TRUE, append=TRUE)\n",
    "cat(recall, file=\"precision_recall_report.txt\", fill=TRUE, append=TRUE)\n",
    "cat(\"\\n\\nPrecision and recall of the test set per lambda.\\n\")\n",
    "cat(\"\\n[L]\\t[P]\\t[R]\\n\")\n",
    "cat(paste(lambdalist, round(precision, digits=4), round(recall, digits=4), sep=\"\\t\"), sep=\"\\n\")\n",
    "cat(\"\\nIt is also saved in precision_recall_report.txt.\\n\")\n",
    "cat(date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d158e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
